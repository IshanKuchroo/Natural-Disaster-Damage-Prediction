{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "858b8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "from math import sqrt, isnan\n",
    "import requests\n",
    "import gzip\n",
    "from functools import reduce\n",
    "import scipy as scp\n",
    "\n",
    "import warnings\n",
    "warnings.catch_warnings()\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "c1cf52fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting CSV files...\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "def get_NOAA_data():\n",
    "    \n",
    "    URL = \"https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/\"\n",
    "    r = requests.get(URL)\n",
    "    file_names = pd.read_html(r.text)[0]['Name']\n",
    "    events_file_names = file_names[file_names.str.contains(\"details\",na=False)]\n",
    "    noaa_list = []\n",
    "    \n",
    "    print(\"Extracting CSV files...\")\n",
    "    for file in events_file_names:\n",
    "        full_URL = URL + file\n",
    "        with gzip.open(requests.get(full_URL, stream=True).raw) as f:\n",
    "            noaa_list.append(pd.read_csv(f))\n",
    "        \n",
    "    df = pd.concat(noaa_list)\n",
    "    \n",
    "    print(\"Completed\")\n",
    "    return df\n",
    "\n",
    "def pickle_source_data():\n",
    "    noaa_source_df = get_NOAA_data()\n",
    "    home_dir = os.getcwd()\n",
    "    data_dir = os.path.join(home_dir, \"Data\")\n",
    "    try:\n",
    "        os.mkdir(data_dir)\n",
    "        os.chdir(data_dir)\n",
    "    except OSError:\n",
    "        os.chdir(data_dir)\n",
    "        for file in os.listdir():\n",
    "            os.remove(file)\n",
    "    noaa_source_df.to_pickle('noaa_source_data.pkl')\n",
    "    os.chdir(home_dir)\n",
    "    return noaa_source_df\n",
    "\n",
    "NOAA_df = pickle_source_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "d76bdd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_df = pd.read_pickle('Data/noaa_source_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "718d5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOAA_df = pd.read_pickle('Data/noaa_source_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "39d05e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_str2num(x):\n",
    "    if type(x) == float or type(x) == int:\n",
    "        return float(x)\n",
    "    num = 1 if x[:-1] == '' else x[:-1]        \n",
    "    if x[-1] == 'T':\n",
    "        return float(num) * 1000000000000\n",
    "    elif x[-1] == 'B':\n",
    "        return float(num) * 1000000000\n",
    "    elif x[-1] == 'M':\n",
    "        return float(num) * 1000000\n",
    "    elif x[-1] == 'K' or x[-1] == 'k':\n",
    "        return float(num) * 1000\n",
    "    elif x[-1] == 'h' or x[-1] == 'H':\n",
    "        return float(num) * 100\n",
    "    elif x[-1] == '?':\n",
    "        return float(num)\n",
    "    else:\n",
    "        return float(x)\n",
    "\n",
    "def winds(x):\n",
    "    if x['MAGNITUDE_TYPE'] in ['EG', 'E', 'M', 'ES', 'MG', 'MS']:\n",
    "        return x['MAGNITUDE']\n",
    "\n",
    "def hail(x):\n",
    "    if x['MAGNITUDE_TYPE'] not in ['EG', 'E', 'M', 'ES', 'MG', 'MS']:\n",
    "        return x['MAGNITUDE']\n",
    "\n",
    "def missing_swap(df, col1, col2):\n",
    "    df.loc[~df[col1].isnull() & df[col2].isnull(), col2] = df.loc[~df[col1].isnull() & df[col2].isnull(), col1]\n",
    "    df.loc[df[col1].isnull() & ~df[col2].isnull(), col1] = df.loc[df[col1].isnull() & ~df[col2].isnull(), col2]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "d90b29aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>...</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "      <th>WIND_SPEED</th>\n",
       "      <th>HAIL_SIZE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>10096222</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>35.12</td>\n",
       "      <td>-99.2</td>\n",
       "      <td>35.17</td>\n",
       "      <td>-99.2</td>\n",
       "      <td>PUB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>10120412</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>31.9</td>\n",
       "      <td>-98.6</td>\n",
       "      <td>31.73</td>\n",
       "      <td>-98.6</td>\n",
       "      <td>PUB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>10104927</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>40.58</td>\n",
       "      <td>-75.7</td>\n",
       "      <td>40.65</td>\n",
       "      <td>-75.47</td>\n",
       "      <td>PUB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1830</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1830</td>\n",
       "      <td>10104928</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>40.6</td>\n",
       "      <td>-76.75</td>\n",
       "      <td>40.6</td>\n",
       "      <td>-76.75</td>\n",
       "      <td>PUB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195007</td>\n",
       "      <td>24</td>\n",
       "      <td>1440</td>\n",
       "      <td>195007</td>\n",
       "      <td>24</td>\n",
       "      <td>1440</td>\n",
       "      <td>10104929</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>41.63</td>\n",
       "      <td>-79.68</td>\n",
       "      <td>41.63</td>\n",
       "      <td>-79.68</td>\n",
       "      <td>PUB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           195004         28        1445         195004       28      1445   \n",
       "1           195004         29        1530         195004       29      1530   \n",
       "2           195007          5        1800         195007        5      1800   \n",
       "3           195007          5        1830         195007        5      1830   \n",
       "4           195007         24        1440         195007       24      1440   \n",
       "\n",
       "   EVENT_ID         STATE STATE_FIPS  YEAR  ... END_RANGE END_AZIMUTH  \\\n",
       "0  10096222      OKLAHOMA       40.0  1950  ...       0.0         N/A   \n",
       "1  10120412         TEXAS       48.0  1950  ...       0.0         N/A   \n",
       "2  10104927  PENNSYLVANIA       42.0  1950  ...       0.0         N/A   \n",
       "3  10104928  PENNSYLVANIA       42.0  1950  ...       0.0         N/A   \n",
       "4  10104929  PENNSYLVANIA       42.0  1950  ...       0.0         N/A   \n",
       "\n",
       "  END_LOCATION  BEGIN_LAT BEGIN_LON END_LAT END_LON DATA_SOURCE WIND_SPEED  \\\n",
       "0          N/A      35.12     -99.2   35.17   -99.2         PUB        0.0   \n",
       "1          N/A       31.9     -98.6   31.73   -98.6         PUB        0.0   \n",
       "2          N/A      40.58     -75.7   40.65  -75.47         PUB        0.0   \n",
       "3          N/A       40.6    -76.75    40.6  -76.75         PUB        0.0   \n",
       "4          N/A      41.63    -79.68   41.63  -79.68         PUB        0.0   \n",
       "\n",
       "   HAIL_SIZE  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def impute_NOAA_data(df):\n",
    "    \n",
    "    # maginitude converted into other variables\n",
    "    drop_list = ['EVENT_NARRATIVE', 'EPISODE_NARRATIVE', 'EPISODE_ID', 'MAGNITUDE']\n",
    "    impute_mean_list = ['BEGIN_LAT', 'END_LAT', 'BEGIN_LON', 'END_LON']\n",
    "    \n",
    "    # imputing damage columns with 0 for the time-being\n",
    "    impute_zero_list = ['TOR_WIDTH', 'TOR_LENGTH', 'BEGIN_RANGE', 'END_RANGE', 'DAMAGE_CROPS', \\\n",
    "                        'DAMAGE_PROPERTY', 'WIND_SPEED', 'HAIL_SIZE']\n",
    "    impute_NA_list = ['TOR_OTHER_CZ_NAME', 'TOR_OTHER_CZ_STATE', 'TOR_OTHER_WFO', 'TOR_F_SCALE', \\\n",
    "                      'CATEGORY', 'FLOOD_CAUSE', 'SOURCE', 'WFO', 'CZ_NAME', 'DATA_SOURCE', 'STATE', \\\n",
    "                      'STATE_FIPS', 'MAGNITUDE_TYPE', 'BEGIN_AZIMUTH', 'END_AZIMUTH', 'BEGIN_LOCATION', \\\n",
    "                      'END_LOCATION', 'TOR_OTHER_CZ_FIPS']\n",
    "    \n",
    "    # Removing inconsistencies\n",
    "    df = missing_swap(df, 'BEGIN_RANGE', 'END_RANGE')\n",
    "    df = missing_swap(df, 'BEGIN_LAT', 'END_LAT')\n",
    "    df = missing_swap(df, 'BEGIN_LON', 'END_LON')\n",
    "    df = missing_swap(df, 'BEGIN_AZIMUTH', 'END_AZIMUTH')\n",
    "    df = missing_swap(df, 'BEGIN_LOCATION', 'END_LOCATION')\n",
    "    \n",
    "    # Damage variables cleaning\n",
    "    df['DAMAGE_PROPERTY'] = df.DAMAGE_PROPERTY.map(replace_str2num)\n",
    "    df['DAMAGE_CROPS'] = df.DAMAGE_CROPS.map(replace_str2num)\n",
    "    \n",
    "    # Splitting magnitude variable into constituent attributes\n",
    "    df['WIND_SPEED'] = df.apply(winds, axis = 1)\n",
    "    df['HAIL_SIZE'] = df.apply(hail, axis = 1)\n",
    "    \n",
    "    # Imputing string columns with missing values with N/A\n",
    "    for col in impute_NA_list:\n",
    "        df[col] = df[col].astype('str').apply(lambda x: 'N/A' if x=='nan' else x)\n",
    "        \n",
    "    # Imputing float columns having missing values with 0.0\n",
    "    for col in impute_zero_list:\n",
    "        df[col] = df[col].fillna(0.0)\n",
    "        \n",
    "    # Imputing latitude and longitudes with average value\n",
    "    for col in impute_mean_list:\n",
    "        df[col] = df[col].fillna(np.mean)\n",
    "        \n",
    "    # Dropping text and ID columns\n",
    "    for col in drop_list:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "imputed_NOAA_df = impute_NOAA_data(NOAA_df.copy())\n",
    "imputed_NOAA_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776cfc04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "e005724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EPA_data():\n",
    "    \n",
    "    ground_temp_df = pd.read_csv('https://www.epa.gov/sites/default/files/2021-04/temperature_fig-1.csv', skiprows=6, usecols = [0, 1], encoding='latin1')\n",
    "    ground_temp_df.columns = [\"YEAR\", \"SURFACE_TEMP_DIFF\"]\n",
    "    \n",
    "    greenhouse_df = pd.read_csv(\"https://www.epa.gov/sites/default/files/2021-04/us-ghg-emissions_fig-1.csv\",skiprows=6)\n",
    "    greenhouse_df.columns = [\"YEAR\", \"CO2\", \"METHANE\", \"N2O\", \"HFC, PFC, SF6, NF3\"]\n",
    "    \n",
    "    precipitation_df =  pd.read_csv('https://www.epa.gov/sites/default/files/2021-04/heavy-precip_fig-1.csv',skiprows=6)\n",
    "    precipitation_df.columns = [\"YEAR\", \"PPT_LAND_AREA\", \"PPT_NINE_YEAR_AVG\"]\n",
    "    \n",
    "    sea_level_df = pd.read_csv('https://www.epa.gov/sites/default/files/2021-04/sea-level_fig-1.csv', skiprows=6)\n",
    "    sea_level_df.columns = [\"YEAR\", \"CSIRO_ADJ_SEA_LEVEL\", \"CSIRO_LOWER\", \"CSIRO_UPPER\", \"NOAA_ADJ_SEA_LEVEL\"]\n",
    "    sea_level_df.loc[sea_level_df['YEAR'] > 1992, 'CSIRO_ADJ_SEA_LEVEL'] = sea_level_df.loc[sea_level_df['YEAR'] > 1992, 'NOAA_ADJ_SEA_LEVEL']\n",
    "    sea_level_df.drop(['CSIRO_LOWER', 'CSIRO_UPPER', 'NOAA_ADJ_SEA_LEVEL'], axis=1, inplace=True)\n",
    "    \n",
    "    seasonal_temp_df = pd.read_csv('https://www.epa.gov/sites/default/files/2021-04/seasonal-temperature_fig-1.csv', skiprows=6)\n",
    "    seasonal_temp_df.columns = [\"YEAR\", \"WINTER_ANOMALY\", \"SPRING_ANOMALY\", \"SUMMER_ANOMALY\", \"FALL_ANOMALY\"]\n",
    "    \n",
    "    arctic_ice_df = pd.read_csv('https://www.epa.gov/sites/default/files/2021-03/arctic-sea-ice_fig-1.csv', skiprows=6)\n",
    "    arctic_ice_df.columns = [\"YEAR\", \"ICE_CVG_MARCH\", \"ICE_CVG_SEP\"]\n",
    "    \n",
    "    glacier_df = pd.read_csv('https://www.epa.gov/sites/default/files/2021-03/glaciers_fig-1.csv', skiprows=6)\n",
    "    glacier_df.columns = [\"YEAR\", \"GLACIER_MASS_BAL\", \"NUM_OBS\"]\n",
    "    glacier_df.drop(['NUM_OBS'], axis=1, inplace=True)\n",
    "    \n",
    "    dfs = [ground_temp_df, greenhouse_df, precipitation_df, sea_level_df, seasonal_temp_df, arctic_ice_df, glacier_df]\n",
    "    epa_df = reduce(lambda left, right: pd.merge(left, right, how=\"outer\", on=\"YEAR\"), dfs)\n",
    "    epa_df = epa_df[epa_df.YEAR >= 1950]\n",
    "    \n",
    "    return epa_df\n",
    "\n",
    "epa_source_df = get_EPA_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "0262bef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SURFACE_TEMP_DIFF</th>\n",
       "      <th>CO2</th>\n",
       "      <th>METHANE</th>\n",
       "      <th>N2O</th>\n",
       "      <th>HFC, PFC, SF6, NF3</th>\n",
       "      <th>PPT_LAND_AREA</th>\n",
       "      <th>PPT_NINE_YEAR_AVG</th>\n",
       "      <th>CSIRO_ADJ_SEA_LEVEL</th>\n",
       "      <th>WINTER_ANOMALY</th>\n",
       "      <th>SPRING_ANOMALY</th>\n",
       "      <th>SUMMER_ANOMALY</th>\n",
       "      <th>FALL_ANOMALY</th>\n",
       "      <th>ICE_CVG_MARCH</th>\n",
       "      <th>ICE_CVG_SEP</th>\n",
       "      <th>GLACIER_MASS_BAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1950</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>702.184832</td>\n",
       "      <td>847.599809</td>\n",
       "      <td>281.857201</td>\n",
       "      <td>-97.772042</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.085488</td>\n",
       "      <td>3.598425</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7.072426</td>\n",
       "      <td>2.654838</td>\n",
       "      <td>3.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1951</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>808.351302</td>\n",
       "      <td>844.625591</td>\n",
       "      <td>285.793109</td>\n",
       "      <td>-93.175619</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.093453</td>\n",
       "      <td>3.972441</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>7.046364</td>\n",
       "      <td>2.657155</td>\n",
       "      <td>2.788667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1952</td>\n",
       "      <td>0.25</td>\n",
       "      <td>914.517772</td>\n",
       "      <td>841.651374</td>\n",
       "      <td>289.729018</td>\n",
       "      <td>-88.579195</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.099285</td>\n",
       "      <td>3.870079</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>7.020303</td>\n",
       "      <td>2.659472</td>\n",
       "      <td>2.461333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1953</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1020.684243</td>\n",
       "      <td>838.677156</td>\n",
       "      <td>293.664926</td>\n",
       "      <td>-83.982772</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.102855</td>\n",
       "      <td>4.043307</td>\n",
       "      <td>3.02</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.87</td>\n",
       "      <td>6.994241</td>\n",
       "      <td>2.661788</td>\n",
       "      <td>2.134000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1954</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1126.850713</td>\n",
       "      <td>835.702938</td>\n",
       "      <td>297.600834</td>\n",
       "      <td>-79.386348</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.101262</td>\n",
       "      <td>3.929134</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.51</td>\n",
       "      <td>6.968179</td>\n",
       "      <td>2.664105</td>\n",
       "      <td>1.806667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR  SURFACE_TEMP_DIFF          CO2     METHANE         N2O  \\\n",
       "49  1950              -0.63   702.184832  847.599809  281.857201   \n",
       "50  1951              -0.90   808.351302  844.625591  285.793109   \n",
       "51  1952               0.25   914.517772  841.651374  289.729018   \n",
       "52  1953               1.35  1020.684243  838.677156  293.664926   \n",
       "53  1954               1.31  1126.850713  835.702938  297.600834   \n",
       "\n",
       "    HFC, PFC, SF6, NF3  PPT_LAND_AREA  PPT_NINE_YEAR_AVG  CSIRO_ADJ_SEA_LEVEL  \\\n",
       "49          -97.772042          0.100           0.085488             3.598425   \n",
       "50          -93.175619          0.107           0.093453             3.972441   \n",
       "51          -88.579195          0.077           0.099285             3.870079   \n",
       "52          -83.982772          0.123           0.102855             4.043307   \n",
       "53          -79.386348          0.099           0.101262             3.929134   \n",
       "\n",
       "    WINTER_ANOMALY  SPRING_ANOMALY  SUMMER_ANOMALY  FALL_ANOMALY  \\\n",
       "49            0.85           -1.94           -1.68          0.32   \n",
       "50            0.35           -1.24           -0.66         -1.49   \n",
       "51            0.67           -0.94            1.16         -0.63   \n",
       "52            3.02           -0.36            0.75          1.87   \n",
       "53            3.10           -0.25            0.77          1.51   \n",
       "\n",
       "    ICE_CVG_MARCH  ICE_CVG_SEP  GLACIER_MASS_BAL  \n",
       "49       7.072426     2.654838          3.116000  \n",
       "50       7.046364     2.657155          2.788667  \n",
       "51       7.020303     2.659472          2.461333  \n",
       "52       6.994241     2.661788          2.134000  \n",
       "53       6.968179     2.664105          1.806667  "
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def impute_EPA_DATA(df, breaks):\n",
    "    fillable_cols = df.columns[df.isnull().sum() > 0]\n",
    "    for col in fillable_cols:\n",
    "        temp_df = df[['YEAR', col]]\n",
    "        present_df = temp_df[~ temp_df[col].isnull()]\n",
    "        null_df = temp_df[temp_df[col].isnull()]\n",
    "        years = sorted(np.random.choice(present_df['YEAR'], breaks))\n",
    "        input_df = present_df[present_df['YEAR'].isin(years)]\n",
    "        func = scp.interpolate.interp1d(input_df['YEAR'], input_df[col], fill_value=\"extrapolate\")\n",
    "        temp_df['INTERPOLATION'] = func(temp_df['YEAR'])\n",
    "        df[col] = temp_df.apply(lambda x: x['INTERPOLATION'] if isnan(x[col]) else x[col], axis=1)\n",
    "    return df\n",
    "        \n",
    "imputed_EPA_df = impute_EPA_DATA(epa_source_df.copy(), 6)\n",
    "imputed_EPA_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "eb7e4bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>...</th>\n",
       "      <th>PPT_LAND_AREA</th>\n",
       "      <th>PPT_NINE_YEAR_AVG</th>\n",
       "      <th>CSIRO_ADJ_SEA_LEVEL</th>\n",
       "      <th>WINTER_ANOMALY</th>\n",
       "      <th>SPRING_ANOMALY</th>\n",
       "      <th>SUMMER_ANOMALY</th>\n",
       "      <th>FALL_ANOMALY</th>\n",
       "      <th>ICE_CVG_MARCH</th>\n",
       "      <th>ICE_CVG_SEP</th>\n",
       "      <th>GLACIER_MASS_BAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>10096222</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.085488</td>\n",
       "      <td>3.598425</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7.072426</td>\n",
       "      <td>2.654838</td>\n",
       "      <td>3.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>10120412</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.085488</td>\n",
       "      <td>3.598425</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7.072426</td>\n",
       "      <td>2.654838</td>\n",
       "      <td>3.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>10104927</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.085488</td>\n",
       "      <td>3.598425</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7.072426</td>\n",
       "      <td>2.654838</td>\n",
       "      <td>3.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1830</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1830</td>\n",
       "      <td>10104928</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.085488</td>\n",
       "      <td>3.598425</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7.072426</td>\n",
       "      <td>2.654838</td>\n",
       "      <td>3.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195007</td>\n",
       "      <td>24</td>\n",
       "      <td>1440</td>\n",
       "      <td>195007</td>\n",
       "      <td>24</td>\n",
       "      <td>1440</td>\n",
       "      <td>10104929</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.085488</td>\n",
       "      <td>3.598425</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7.072426</td>\n",
       "      <td>2.654838</td>\n",
       "      <td>3.116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           195004         28        1445         195004       28      1445   \n",
       "1           195004         29        1530         195004       29      1530   \n",
       "2           195007          5        1800         195007        5      1800   \n",
       "3           195007          5        1830         195007        5      1830   \n",
       "4           195007         24        1440         195007       24      1440   \n",
       "\n",
       "   EVENT_ID         STATE STATE_FIPS  YEAR  ... PPT_LAND_AREA  \\\n",
       "0  10096222      OKLAHOMA       40.0  1950  ...           0.1   \n",
       "1  10120412         TEXAS       48.0  1950  ...           0.1   \n",
       "2  10104927  PENNSYLVANIA       42.0  1950  ...           0.1   \n",
       "3  10104928  PENNSYLVANIA       42.0  1950  ...           0.1   \n",
       "4  10104929  PENNSYLVANIA       42.0  1950  ...           0.1   \n",
       "\n",
       "  PPT_NINE_YEAR_AVG CSIRO_ADJ_SEA_LEVEL  WINTER_ANOMALY SPRING_ANOMALY  \\\n",
       "0          0.085488            3.598425            0.85          -1.94   \n",
       "1          0.085488            3.598425            0.85          -1.94   \n",
       "2          0.085488            3.598425            0.85          -1.94   \n",
       "3          0.085488            3.598425            0.85          -1.94   \n",
       "4          0.085488            3.598425            0.85          -1.94   \n",
       "\n",
       "  SUMMER_ANOMALY FALL_ANOMALY ICE_CVG_MARCH ICE_CVG_SEP  GLACIER_MASS_BAL  \n",
       "0          -1.68         0.32      7.072426    2.654838             3.116  \n",
       "1          -1.68         0.32      7.072426    2.654838             3.116  \n",
       "2          -1.68         0.32      7.072426    2.654838             3.116  \n",
       "3          -1.68         0.32      7.072426    2.654838             3.116  \n",
       "4          -1.68         0.32      7.072426    2.654838             3.116  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = pd.merge(imputed_NOAA_df, imputed_EPA_df, on='YEAR', how='inner')\n",
    "cleaned_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
