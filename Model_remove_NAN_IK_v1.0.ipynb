{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "view-in-github",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/siddas18/Natural-Disaster-Damage-Prediction/blob/Kartik/Data_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "MgmFTvS9ZlB0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15846,
     "status": "ok",
     "timestamp": 1638594244347,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "MgmFTvS9ZlB0",
    "outputId": "c23c0157-cfc0-4766-ae3e-2d31d103c828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "858b8ba7",
   "metadata": {
    "executionInfo": {
     "elapsed": 1075,
     "status": "ok",
     "timestamp": 1638594245418,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "858b8ba7"
   },
   "outputs": [],
   "source": [
    "# Generic Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "from math import sqrt, isnan, pi, sin, cos, atan2\n",
    "import requests\n",
    "import gzip\n",
    "from functools import reduce\n",
    "import scipy as scp\n",
    "import seaborn as sns\n",
    "import scipy.interpolate\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.catch_warnings()\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf52fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86376,
     "status": "ok",
     "timestamp": 1638574361250,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "c1cf52fb",
    "outputId": "8942db45-5079-40c3-f796-0c77c0fb939c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting CSV files...\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "def get_NOAA_data():\n",
    "    \n",
    "    URL = \"https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/\"\n",
    "    r = requests.get(URL)\n",
    "    file_names = pd.read_html(r.text)[0]['Name']\n",
    "    events_file_names = file_names[file_names.str.contains(\"details\",na=False)]\n",
    "    noaa_list = []\n",
    "    \n",
    "    print(\"Extracting CSV files...\")\n",
    "    for file in events_file_names:\n",
    "        full_URL = URL + file\n",
    "        with gzip.open(requests.get(full_URL, stream=True).raw) as f:\n",
    "            noaa_list.append(pd.read_csv(f))\n",
    "        \n",
    "    df = pd.concat(noaa_list)\n",
    "    \n",
    "    print(\"Completed\")\n",
    "    return df\n",
    "\n",
    "def pickle_source_data():\n",
    "    noaa_source_df = get_NOAA_data()\n",
    "    home_dir = os.getcwd()\n",
    "    data_dir = os.path.join(home_dir, \"Data\")\n",
    "    try:\n",
    "        os.mkdir(data_dir)\n",
    "        os.chdir(data_dir)\n",
    "    except OSError:\n",
    "        os.chdir(data_dir)\n",
    "        for file in os.listdir():\n",
    "            os.remove(file)\n",
    "    noaa_source_df.to_pickle('noaa_source_data.pkl')\n",
    "    os.chdir(home_dir)\n",
    "    return noaa_source_df\n",
    "\n",
    "NOAA_df = pickle_source_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "718d5efd",
   "metadata": {
    "executionInfo": {
     "elapsed": 12239,
     "status": "ok",
     "timestamp": 1638594264983,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "718d5efd"
   },
   "outputs": [],
   "source": [
    "NOAA_df = pd.read_pickle('Data/noaa_source_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39d05e20",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1638594265646,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "39d05e20"
   },
   "outputs": [],
   "source": [
    "def replace_str2num(x):\n",
    "    if type(x) == float or type(x) == int:\n",
    "        return float(x)\n",
    "    num = 1 if x[:-1] == '' else x[:-1]        \n",
    "    if x[-1] == 'T':\n",
    "        return float(num) * 1000000000000\n",
    "    elif x[-1] == 'B':\n",
    "        return float(num) * 1000000000\n",
    "    elif x[-1] == 'M':\n",
    "        return float(num) * 1000000\n",
    "    elif x[-1] == 'K' or x[-1] == 'k':\n",
    "        return float(num) * 1000\n",
    "    elif x[-1] == 'h' or x[-1] == 'H':\n",
    "        return float(num) * 100\n",
    "    elif x[-1] == '?':\n",
    "        return float(num)\n",
    "    else:\n",
    "        return float(x)\n",
    "\n",
    "def winds(x):\n",
    "    if x['MAGNITUDE_TYPE'] in ['EG', 'E', 'M', 'ES', 'MG', 'MS']:\n",
    "        return x['MAGNITUDE']\n",
    "\n",
    "def hail(x):\n",
    "    if x['MAGNITUDE_TYPE'] not in ['EG', 'E', 'M', 'ES', 'MG', 'MS']:\n",
    "        return x['MAGNITUDE']\n",
    "\n",
    "def missing_swap(df, col1, col2):\n",
    "    df.loc[~df[col1].isnull() & df[col2].isnull(), col2] = df.loc[~df[col1].isnull() & df[col2].isnull(), col1]\n",
    "    df.loc[df[col1].isnull() & ~df[col2].isnull(), col1] = df.loc[df[col1].isnull() & ~df[col2].isnull(), col2]\n",
    "    return df\n",
    "\n",
    "rename_event_dict = {\n",
    "    'TORNADOES, TSTM WIND, HAIL': 'Tornadoes, Thunderstorm Wind, Hail',\n",
    "    'THUNDERSTORM WINDS LIGHTNING': 'Thunderstorm Wind, Lightning',\n",
    "    'THUNDERSTORM WINDS/ FLOOD': 'Thunderstorm Wind, Flood',\n",
    "    'THUNDERSTORM WINDS/FLOODING': 'Thunderstorm Wind, Flood',\n",
    "    'THUNDERSTORM WIND/ TREES': 'Thunderstorm Wind, Trees',\n",
    "    'THUNDERSTORM WIND/ TREE': 'Thunderstorm Wind, Trees',\n",
    "    'THUNDERSTORM WINDS/HEAVY RAIN': 'Thunderstorm Wind, Heavy Rain',\n",
    "    'TORNADO/WATERSPOUT': 'Tornado, Waterspout',\n",
    "    'THUNDERSTORM WINDS FUNNEL CLOU': 'Thunderstorm Wind, Funnel Cloud',\n",
    "    'THUNDERSTORM WINDS/FLASH FLOOD': 'Thunderstorm Wind, Flash Flood',\n",
    "    'HAIL/ICY ROADS': 'Hail, Icy Roads',\n",
    "    'HAIL FLOODING': 'Hail, Flood',\n",
    "    'THUNDERSTORM WINDS HEAVY RAIN': 'Thunderstorm Wind, Heavy Rain',\n",
    "    'Hurricane (Typhoon)': 'Hurricane'\n",
    "}\n",
    "\n",
    "timezone_dict = {\n",
    "    'GST' : ['GST10'],\n",
    "    'AST' : ['AST-4', 'AST'],\n",
    "    'EST' : ['EST', 'EST-5', 'ESt', 'EDT'],\n",
    "    'CST' : ['CST', 'CST-6', 'CSt', 'CSC', 'SCT', 'GMT', 'UNK', 'CDT'],\n",
    "    'MST' : ['MST', 'MST-7', 'MDT'],\n",
    "    'PST' : ['PST', 'PST-8', 'PDT'],\n",
    "    'AKST': ['AKST-9'],\n",
    "    'HST' : ['HST-10', 'HST'],\n",
    "    'SST' : ['SST-11', 'SST']\n",
    "}\n",
    "\n",
    "def timezone_mapping(x):\n",
    "    for key, val in timezone_dict.items():\n",
    "        if x in val:\n",
    "            return key\n",
    "\n",
    "azimuth_mapping ={ 'N/A': ['ND', 'EE', 'TO', 'MI', 'M', 'EST', 'EAS', 'TH', 'WES'] }\n",
    "\n",
    "def dict_mapping(x):\n",
    "    for key, val in timezone_dict.items():\n",
    "        if x in val:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5WSMA4Tvp3ZB",
   "metadata": {
    "executionInfo": {
     "elapsed": 3136,
     "status": "ok",
     "timestamp": 1638594268779,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "5WSMA4Tvp3ZB"
   },
   "outputs": [],
   "source": [
    "# Damage variables cleaning\n",
    "\n",
    "NOAA_df['DAMAGE_PROPERTY'] = NOAA_df.DAMAGE_PROPERTY.map(replace_str2num)\n",
    "\n",
    "NOAA_df['DAMAGE_CROPS'] = NOAA_df.DAMAGE_CROPS.map(replace_str2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "TWISm0x2tdCp",
   "metadata": {
    "id": "TWISm0x2tdCp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE_ID : 232016 \n",
      "\n",
      "13.568798127167131 \n",
      "\n",
      "STATE : 1 \n",
      "\n",
      "5.848216557119823e-05 \n",
      "\n",
      "STATE_FIPS : 1 \n",
      "\n",
      "5.848216557119823e-05 \n",
      "\n",
      "CZ_NAME : 1557 \n",
      "\n",
      "0.09105673179435565 \n",
      "\n",
      "WFO : 125350 \n",
      "\n",
      "7.330739454349698 \n",
      "\n",
      "DAMAGE_PROPERTY : 544204 \n",
      "\n",
      "31.826228432508362 \n",
      "\n",
      "DAMAGE_CROPS : 655519 \n",
      "\n",
      "38.33617069306629 \n",
      "\n",
      "SOURCE : 345642 \n",
      "\n",
      "20.2138926723601 \n",
      "\n",
      "MAGNITUDE : 716476 \n",
      "\n",
      "41.90106805978983 \n",
      "\n",
      "MAGNITUDE_TYPE : 1284042 \n",
      "\n",
      "75.09355684437253 \n",
      "\n",
      "FLOOD_CAUSE : 1612631 \n",
      "\n",
      "94.31015314724698 \n",
      "\n",
      "CATEGORY : 1709479 \n",
      "\n",
      "99.97403391848638 \n",
      "\n",
      "TOR_F_SCALE : 1639007 \n",
      "\n",
      "95.85267874635291 \n",
      "\n",
      "TOR_LENGTH : 1442367 \n",
      "\n",
      "84.35274570843248 \n",
      "\n",
      "TOR_WIDTH : 1442367 \n",
      "\n",
      "84.35274570843248 \n",
      "\n",
      "TOR_OTHER_WFO : 1707365 \n",
      "\n",
      "99.85040262046887 \n",
      "\n",
      "TOR_OTHER_CZ_STATE : 1707365 \n",
      "\n",
      "99.85040262046887 \n",
      "\n",
      "TOR_OTHER_CZ_FIPS : 1707365 \n",
      "\n",
      "99.85040262046887 \n",
      "\n",
      "TOR_OTHER_CZ_NAME : 1707365 \n",
      "\n",
      "99.85040262046887 \n",
      "\n",
      "BEGIN_RANGE : 766318 \n",
      "\n",
      "44.81593615618949 \n",
      "\n",
      "BEGIN_AZIMUTH : 984815 \n",
      "\n",
      "57.59411388699959 \n",
      "\n",
      "BEGIN_LOCATION : 733907 \n",
      "\n",
      "42.92047068786138 \n",
      "\n",
      "END_RANGE : 766695 \n",
      "\n",
      "44.83798393260983 \n",
      "\n",
      "END_AZIMUTH : 997896 \n",
      "\n",
      "58.35911909483643 \n",
      "\n",
      "END_LOCATION : 773263 \n",
      "\n",
      "45.222094796081464 \n",
      "\n",
      "BEGIN_LAT : 649754 \n",
      "\n",
      "37.99902100854834 \n",
      "\n",
      "BEGIN_LON : 649761 \n",
      "\n",
      "37.99943038370734 \n",
      "\n",
      "END_LAT : 827135 \n",
      "\n",
      "48.372646019733054 \n",
      "\n",
      "END_LON : 827141 \n",
      "\n",
      "48.37299691272648 \n",
      "\n",
      "EPISODE_NARRATIVE : 478885 \n",
      "\n",
      "28.006231859563268 \n",
      "\n",
      "EVENT_NARRATIVE : 845117 \n",
      "\n",
      "49.42427232103434 \n",
      "\n",
      "DATA_SOURCE : 3 \n",
      "\n",
      "0.0001754464967135947 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using data after Year 1950 and checking how many columns have NULL values\n",
    "\n",
    "NOAA_df = NOAA_df[NOAA_df['YEAR']> 1950]\n",
    "\n",
    "for i in NOAA_df.columns:\n",
    "    if NOAA_df[i].isna().sum() > 0:\n",
    "        print(NOAA_df[i].name, \":\", NOAA_df[i].isna().sum(), \"\\n\")\n",
    "        print((NOAA_df[i].isna().sum()/NOAA_df.shape[0])*100, \"\\n\")\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "n9qVb6-NkmqK",
   "metadata": {
    "executionInfo": {
     "elapsed": 1638,
     "status": "ok",
     "timestamp": 1638594291251,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "n9qVb6-NkmqK"
   },
   "outputs": [],
   "source": [
    "# Removing inconsistencies\n",
    "NOAA_df = missing_swap(NOAA_df, 'BEGIN_RANGE', 'END_RANGE')\n",
    "NOAA_df = missing_swap(NOAA_df, 'BEGIN_LAT', 'END_LAT')\n",
    "NOAA_df = missing_swap(NOAA_df, 'BEGIN_LON', 'END_LON')\n",
    "NOAA_df = missing_swap(NOAA_df, 'BEGIN_AZIMUTH', 'END_AZIMUTH')\n",
    "NOAA_df = missing_swap(NOAA_df, 'BEGIN_LOCATION', 'END_LOCATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "tyF5UDw0-Cir",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10039,
     "status": "ok",
     "timestamp": 1638594301288,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "tyF5UDw0-Cir",
    "outputId": "1972f3b8-084b-4627-9e4c-15d162f6e453"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198875, 51)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing Outliers\n",
    "\n",
    "NOAA_df.shape\n",
    "\n",
    "Q1 = NOAA_df.quantile(0.25)\n",
    "Q3 = NOAA_df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "NOAA_df = NOAA_df[~((NOAA_df < (Q1 - 1.5 * IQR)) |(NOAA_df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "NOAA_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "NjKd_jqswGVI",
   "metadata": {
    "executionInfo": {
     "elapsed": 31341,
     "status": "ok",
     "timestamp": 1638594332620,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "NjKd_jqswGVI"
   },
   "outputs": [],
   "source": [
    "# calculating distance w.r.t Latitude and Longitude\n",
    "\n",
    "def geo_distance(x):\n",
    "    # Source : https://en.wikipedia.org/wiki/Haversine_formula\n",
    "    p = pi/180\n",
    "    lat1 = x['BEGIN_LAT']\n",
    "    lat2 = x['END_LAT']\n",
    "    lon1 = x['BEGIN_LON']\n",
    "    lon2 = x['END_LON']\n",
    "    R = 6371\n",
    "    dLat = p * (lat2-lat1)\n",
    "    dLon = p * (lon2-lon1)\n",
    "    a = sin(dLat/2) * 2 + cos(p*lat1) * cos(p*lat2) * sin(dLon/2) * 2\n",
    "    if a < 0 :\n",
    "      return a\n",
    "    else:\n",
    "      return 2 * R * atan2(sqrt(a), sqrt(1-a))\n",
    "\n",
    "NOAA_df['GEO_DISTANCE'] = NOAA_df.apply(lambda x: geo_distance(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0CdjBM8pYe4O",
   "metadata": {
    "executionInfo": {
     "elapsed": 54073,
     "status": "ok",
     "timestamp": 1638594386689,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "0CdjBM8pYe4O"
   },
   "outputs": [],
   "source": [
    "# NOAA_df['DURATION_OF_STORM'] = (pd.to_datetime(NOAA_df['END_DATE_TIME']) - pd.to_datetime(NOAA_df['BEGIN_DATE_TIME']))\n",
    "# NOAA_df['DURATION_OF_STORM'] = NOAA_df['DURATION_OF_STORM'].astype('str').str[:-13]\n",
    "\n",
    "# calculate duration of the storm event\n",
    "\n",
    "def calc_duration(x):\n",
    "    begin_dt = dt.strptime(x['BEGIN_DATE_TIME'], \"%d-%b-%y %H:%M:%S\")\n",
    "    end_dt = dt.strptime(x['END_DATE_TIME'], \"%d-%b-%y %H:%M:%S\")\n",
    "    difference = end_dt - begin_dt\n",
    "    difference_days = difference.days + difference.seconds/86400\n",
    "    return difference_days\n",
    "\n",
    "NOAA_df['DURATION_OF_STORM'] = NOAA_df.apply(lambda x: calc_duration(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "m8ybWSVAvrLY",
   "metadata": {
    "id": "m8ybWSVAvrLY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "      <th>GEO_DISTANCE</th>\n",
       "      <th>DURATION_OF_STORM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197908</td>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>197908</td>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9986735</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.98</td>\n",
       "      <td>-103.58</td>\n",
       "      <td>39.9800</td>\n",
       "      <td>-103.5800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197908</td>\n",
       "      <td>15</td>\n",
       "      <td>2000</td>\n",
       "      <td>197908</td>\n",
       "      <td>15</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9986736</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.77</td>\n",
       "      <td>-104.88</td>\n",
       "      <td>39.7700</td>\n",
       "      <td>-104.8800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197908</td>\n",
       "      <td>16</td>\n",
       "      <td>1930</td>\n",
       "      <td>197908</td>\n",
       "      <td>16</td>\n",
       "      <td>1930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9986737</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.67</td>\n",
       "      <td>-105.02</td>\n",
       "      <td>39.6700</td>\n",
       "      <td>-105.0200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197908</td>\n",
       "      <td>18</td>\n",
       "      <td>1500</td>\n",
       "      <td>197908</td>\n",
       "      <td>18</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9986738</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.07</td>\n",
       "      <td>-105.50</td>\n",
       "      <td>40.0700</td>\n",
       "      <td>-105.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197908</td>\n",
       "      <td>18</td>\n",
       "      <td>1700</td>\n",
       "      <td>197908</td>\n",
       "      <td>18</td>\n",
       "      <td>1700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9986739</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.13</td>\n",
       "      <td>-103.70</td>\n",
       "      <td>39.1300</td>\n",
       "      <td>-103.7000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47043</th>\n",
       "      <td>202106</td>\n",
       "      <td>13</td>\n",
       "      <td>1430</td>\n",
       "      <td>202106</td>\n",
       "      <td>13</td>\n",
       "      <td>1630</td>\n",
       "      <td>160145.0</td>\n",
       "      <td>968777</td>\n",
       "      <td>KENTUCKY</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>PAYNES DEPOT</td>\n",
       "      <td>38.19</td>\n",
       "      <td>-84.65</td>\n",
       "      <td>38.1815</td>\n",
       "      <td>-84.6156</td>\n",
       "      <td>Central Kentucky sat under the leading edge of...</td>\n",
       "      <td>There was flooding at a home on the 3900 block...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>190.105409</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47044</th>\n",
       "      <td>202106</td>\n",
       "      <td>13</td>\n",
       "      <td>1430</td>\n",
       "      <td>202106</td>\n",
       "      <td>13</td>\n",
       "      <td>1630</td>\n",
       "      <td>160145.0</td>\n",
       "      <td>968778</td>\n",
       "      <td>KENTUCKY</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE SULPHER</td>\n",
       "      <td>38.21</td>\n",
       "      <td>-84.67</td>\n",
       "      <td>38.2101</td>\n",
       "      <td>-84.6709</td>\n",
       "      <td>Central Kentucky sat under the leading edge of...</td>\n",
       "      <td>A house flooded on the 100 block of Joshua Cou...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47045</th>\n",
       "      <td>202106</td>\n",
       "      <td>13</td>\n",
       "      <td>1430</td>\n",
       "      <td>202106</td>\n",
       "      <td>13</td>\n",
       "      <td>1630</td>\n",
       "      <td>160145.0</td>\n",
       "      <td>968781</td>\n",
       "      <td>KENTUCKY</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE SULPHER</td>\n",
       "      <td>38.21</td>\n",
       "      <td>-84.68</td>\n",
       "      <td>38.2111</td>\n",
       "      <td>-84.6607</td>\n",
       "      <td>Central Kentucky sat under the leading edge of...</td>\n",
       "      <td>A home basement flooded on the 3600 block of F...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>192.055144</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47046</th>\n",
       "      <td>202106</td>\n",
       "      <td>13</td>\n",
       "      <td>1530</td>\n",
       "      <td>202106</td>\n",
       "      <td>13</td>\n",
       "      <td>1730</td>\n",
       "      <td>160145.0</td>\n",
       "      <td>968782</td>\n",
       "      <td>KENTUCKY</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>STAMPING GROUND</td>\n",
       "      <td>38.28</td>\n",
       "      <td>-84.70</td>\n",
       "      <td>38.2775</td>\n",
       "      <td>-84.6971</td>\n",
       "      <td>Central Kentucky sat under the leading edge of...</td>\n",
       "      <td>Owenton Road was flooded between Cedar Road an...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47047</th>\n",
       "      <td>202106</td>\n",
       "      <td>12</td>\n",
       "      <td>2230</td>\n",
       "      <td>202106</td>\n",
       "      <td>12</td>\n",
       "      <td>2230</td>\n",
       "      <td>159367.0</td>\n",
       "      <td>963844</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>GRIGGS</td>\n",
       "      <td>36.60</td>\n",
       "      <td>-102.12</td>\n",
       "      <td>36.6000</td>\n",
       "      <td>-102.1200</td>\n",
       "      <td>A weak upper level disturbance moved along the...</td>\n",
       "      <td>Three limbs snapped and shed was shifted off i...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1198875 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  \\\n",
       "0               197908          8        2000         197908        8   \n",
       "1               197908         15        2000         197908       15   \n",
       "2               197908         16        1930         197908       16   \n",
       "3               197908         18        1500         197908       18   \n",
       "4               197908         18        1700         197908       18   \n",
       "...                ...        ...         ...            ...      ...   \n",
       "47043           202106         13        1430         202106       13   \n",
       "47044           202106         13        1430         202106       13   \n",
       "47045           202106         13        1430         202106       13   \n",
       "47046           202106         13        1530         202106       13   \n",
       "47047           202106         12        2230         202106       12   \n",
       "\n",
       "       END_TIME  EPISODE_ID  EVENT_ID     STATE  STATE_FIPS  ...  \\\n",
       "0          2000         NaN   9986735  COLORADO         8.0  ...   \n",
       "1          2000         NaN   9986736  COLORADO         8.0  ...   \n",
       "2          1930         NaN   9986737  COLORADO         8.0  ...   \n",
       "3          1500         NaN   9986738  COLORADO         8.0  ...   \n",
       "4          1700         NaN   9986739  COLORADO         8.0  ...   \n",
       "...         ...         ...       ...       ...         ...  ...   \n",
       "47043      1630    160145.0    968777  KENTUCKY        21.0  ...   \n",
       "47044      1630    160145.0    968778  KENTUCKY        21.0  ...   \n",
       "47045      1630    160145.0    968781  KENTUCKY        21.0  ...   \n",
       "47046      1730    160145.0    968782  KENTUCKY        21.0  ...   \n",
       "47047      2230    159367.0    963844  OKLAHOMA        40.0  ...   \n",
       "\n",
       "          END_LOCATION BEGIN_LAT BEGIN_LON  END_LAT   END_LON  \\\n",
       "0                  NaN     39.98   -103.58  39.9800 -103.5800   \n",
       "1                  NaN     39.77   -104.88  39.7700 -104.8800   \n",
       "2                  NaN     39.67   -105.02  39.6700 -105.0200   \n",
       "3                  NaN     40.07   -105.50  40.0700 -105.5000   \n",
       "4                  NaN     39.13   -103.70  39.1300 -103.7000   \n",
       "...                ...       ...       ...      ...       ...   \n",
       "47043     PAYNES DEPOT     38.19    -84.65  38.1815  -84.6156   \n",
       "47044    WHITE SULPHER     38.21    -84.67  38.2101  -84.6709   \n",
       "47045    WHITE SULPHER     38.21    -84.68  38.2111  -84.6607   \n",
       "47046  STAMPING GROUND     38.28    -84.70  38.2775  -84.6971   \n",
       "47047           GRIGGS     36.60   -102.12  36.6000 -102.1200   \n",
       "\n",
       "                                       EPISODE_NARRATIVE  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "47043  Central Kentucky sat under the leading edge of...   \n",
       "47044  Central Kentucky sat under the leading edge of...   \n",
       "47045  Central Kentucky sat under the leading edge of...   \n",
       "47046  Central Kentucky sat under the leading edge of...   \n",
       "47047  A weak upper level disturbance moved along the...   \n",
       "\n",
       "                                         EVENT_NARRATIVE DATA_SOURCE  \\\n",
       "0                                                    NaN         PUB   \n",
       "1                                                    NaN         PUB   \n",
       "2                                                    NaN         PUB   \n",
       "3                                                    NaN         PUB   \n",
       "4                                                    NaN         PUB   \n",
       "...                                                  ...         ...   \n",
       "47043  There was flooding at a home on the 3900 block...         CSV   \n",
       "47044  A house flooded on the 100 block of Joshua Cou...         CSV   \n",
       "47045  A home basement flooded on the 3600 block of F...         CSV   \n",
       "47046  Owenton Road was flooded between Cedar Road an...         CSV   \n",
       "47047  Three limbs snapped and shed was shifted off i...         CSV   \n",
       "\n",
       "      GEO_DISTANCE DURATION_OF_STORM  \n",
       "0         0.000000          0.000000  \n",
       "1         0.000000          0.000000  \n",
       "2         0.000000          0.000000  \n",
       "3         0.000000          0.000000  \n",
       "4         0.000000          0.000000  \n",
       "...            ...               ...  \n",
       "47043   190.105409          0.083333  \n",
       "47044    -0.000008          0.083333  \n",
       "47045   192.055144          0.083333  \n",
       "47046    -0.000012          0.083333  \n",
       "47047     0.000000          0.000000  \n",
       "\n",
       "[1198875 rows x 53 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update EVENT_TYPE column\n",
    "\n",
    "NOAA_df.replace({'EVENT_TYPE' : { 'THUNDERSTORMWIND/TREE' : 'ThunderstormWind', 'THUNDERSTORMWIND/TREES' : 'ThunderstormWind', 'THUNDERSTORMWINDS/FLASHFLOOD' : 'ThunderstormWind'\n",
    "                                 , 'THUNDERSTORMWINDS/FLOODING' : 'ThunderstormWind', 'THUNDERSTORMWINDS/HEAVYRAIN' : 'ThunderstormWind'\n",
    "                                 , 'THUNDERSTORMWINDSFUNNELCLOU': 'ThunderstormWind', 'THUNDERSTORMWINDSHEAVYRAIN': 'ThunderstormWind'\n",
    "                                 , 'THUNDERSTORMWINDSLIGHTNING': 'ThunderstormWind'\n",
    "                                 , 'HAIL/ICYROADS': 'Hail', 'HAILFLOODING': 'Hail', 'Hurricane(Typhoon)': 'Hurricane'}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8Vg5aFrTqlBA",
   "metadata": {
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1638594387810,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "8Vg5aFrTqlBA"
   },
   "outputs": [],
   "source": [
    "# Dropping NAN values - if required\n",
    "\n",
    "NOAA_df.dropna(subset=[\"DAMAGE_PROPERTY\"], inplace=True)\n",
    "# NOAA_df.dropna(subset=[\"DAMAGE_CROPS\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0Rg23j8anZa7",
   "metadata": {
    "executionInfo": {
     "elapsed": 10549,
     "status": "ok",
     "timestamp": 1638594398968,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "0Rg23j8anZa7"
   },
   "outputs": [],
   "source": [
    "# impute DAMAGE_CROPS with mean value of damage per EVENT_TYPE\n",
    "\n",
    "X = NOAA_df.groupby('EVENT_TYPE')\n",
    "\n",
    "Y = X['DAMAGE_CROPS'].mean()\n",
    "\n",
    "reset_index = Y.reset_index()\n",
    "\n",
    "NOAA_df = pd.merge(NOAA_df, reset_index, on='EVENT_TYPE', how='inner')\n",
    "\n",
    "NOAA_df.drop(columns=['DAMAGE_CROPS_x'], inplace=True)\n",
    "\n",
    "NOAA_df = NOAA_df.rename(columns={\"DAMAGE_CROPS_y\": \"DAMAGE_CROPS\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d90b29aa",
   "metadata": {
    "id": "d90b29aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH_NAME</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>CZ_TYPE</th>\n",
       "      <th>CZ_NAME</th>\n",
       "      <th>CZ_TIMEZONE</th>\n",
       "      <th>INJURIES_DIRECT</th>\n",
       "      <th>INJURIES_INDIRECT</th>\n",
       "      <th>DEATHS_DIRECT</th>\n",
       "      <th>...</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>GEO_DISTANCE</th>\n",
       "      <th>DURATION_OF_STORM</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "      <th>WIND_SPEED</th>\n",
       "      <th>HAIL_SIZE</th>\n",
       "      <th>COLD_WEATHER_EVENT</th>\n",
       "      <th>WINDY_EVENT</th>\n",
       "      <th>WATER_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COLORADO</td>\n",
       "      <td>1979</td>\n",
       "      <td>August</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>C</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>CST</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COLORADO</td>\n",
       "      <td>1979</td>\n",
       "      <td>August</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>C</td>\n",
       "      <td>LARIMER</td>\n",
       "      <td>CST</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COLORADO</td>\n",
       "      <td>1979</td>\n",
       "      <td>August</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>C</td>\n",
       "      <td>ADAMS</td>\n",
       "      <td>CST</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COLORADO</td>\n",
       "      <td>1979</td>\n",
       "      <td>August</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>C</td>\n",
       "      <td>MORGAN</td>\n",
       "      <td>CST</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COLORADO</td>\n",
       "      <td>1979</td>\n",
       "      <td>August</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>C</td>\n",
       "      <td>LOGAN</td>\n",
       "      <td>CST</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      STATE  YEAR MONTH_NAME         EVENT_TYPE CZ_TYPE     CZ_NAME  \\\n",
       "0  COLORADO  1979     August  Thunderstorm Wind       C  WASHINGTON   \n",
       "1  COLORADO  1979     August  Thunderstorm Wind       C     LARIMER   \n",
       "2  COLORADO  1979     August  Thunderstorm Wind       C       ADAMS   \n",
       "3  COLORADO  1979     August  Thunderstorm Wind       C      MORGAN   \n",
       "4  COLORADO  1979     August  Thunderstorm Wind       C       LOGAN   \n",
       "\n",
       "  CZ_TIMEZONE  INJURIES_DIRECT  INJURIES_INDIRECT  DEATHS_DIRECT  ...  \\\n",
       "0         CST                0                  0              0  ...   \n",
       "1         CST                0                  0              0  ...   \n",
       "2         CST                0                  0              0  ...   \n",
       "3         CST                0                  0              0  ...   \n",
       "4         CST                0                  0              0  ...   \n",
       "\n",
       "   END_AZIMUTH  END_LOCATION GEO_DISTANCE DURATION_OF_STORM DAMAGE_CROPS  \\\n",
       "0           NA            NA          0.0               0.0          0.0   \n",
       "1           NA            NA          0.0               0.0          0.0   \n",
       "2           NA            NA          0.0               0.0          0.0   \n",
       "3           NA            NA          0.0               0.0          0.0   \n",
       "4           NA            NA          0.0               0.0          0.0   \n",
       "\n",
       "   WIND_SPEED  HAIL_SIZE COLD_WEATHER_EVENT WINDY_EVENT  WATER_EVENT  \n",
       "0         0.0       56.0                  0           1            0  \n",
       "1         0.0       50.0                  0           1            0  \n",
       "2         0.0       50.0                  0           1            0  \n",
       "3         0.0       61.0                  0           1            0  \n",
       "4         0.0        0.0                  0           1            0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def impute_NOAA_data(df):\n",
    "    \n",
    "    # magnitude converted into other variables\n",
    "    drop_list = ['EVENT_NARRATIVE', 'EPISODE_NARRATIVE', 'EPISODE_ID', 'MAGNITUDE', 'BEGIN_LAT', 'END_LAT', 'BEGIN_LON', 'END_LON','BEGIN_DATE_TIME','END_DATE_TIME','STATE_FIPS'\n",
    "                , 'TOR_OTHER_CZ_FIPS', 'WFO', 'SOURCE', 'CATEGORY', 'CZ_FIPS','DATA_SOURCE', 'TOR_OTHER_WFO', 'EVENT_ID', 'BEGIN_YEARMONTH','BEGIN_DAY','BEGIN_TIME', 'END_YEARMONTH'\n",
    "                , 'END_DAY', 'END_TIME']\n",
    "    #  impute_mean_list = ['BEGIN_LAT', 'END_LAT', 'BEGIN_LON', 'END_LON'] # removed because for events like DROUGHT there should be no travelled distance and added to drop list\n",
    "    # Instead impute GEO_DISTANCE to 0\n",
    "    \n",
    "    # imputing damage columns with 0 for the time-being\n",
    "    impute_zero_list = ['BEGIN_RANGE', 'END_RANGE', 'WIND_SPEED', 'HAIL_SIZE','GEO_DISTANCE', 'TOR_LENGTH' ,'TOR_WIDTH']\n",
    "    # ['BEGIN_RANGE', 'END_RANGE', 'WIND_SPEED', 'HAIL_SIZE','GEO_DISTANCE', 'TOR_LENGTH' ,'TOR_WIDTH', 'DAMAGE_PROPERTY']\n",
    "\n",
    "    impute_NA_list = ['CZ_NAME', 'STATE', 'MAGNITUDE_TYPE', 'BEGIN_AZIMUTH', 'END_AZIMUTH', 'BEGIN_LOCATION', 'END_LOCATION', 'FLOOD_CAUSE', 'TOR_F_SCALE'\n",
    "                    , 'TOR_OTHER_CZ_STATE', 'TOR_OTHER_CZ_NAME']\n",
    "      \n",
    "    # Splitting magnitude variable into constituent attributes\n",
    "    df['WIND_SPEED'] = df.apply(winds, axis = 1)\n",
    "    df['HAIL_SIZE'] = df.apply(hail, axis = 1)\n",
    "    \n",
    "    df['EVENT_TYPE'] = df['EVENT_TYPE'].apply(lambda x: rename_event_dict[x] if rename_event_dict.get(x)!= None else x)\n",
    "    df['COLD_WEATHER_EVENT'] = df['EVENT_TYPE'].str.contains('Hail|Winter|Snow|Chill|Cold|Frost|Freeze|Blizzard|Ice|Avalanche').map({True: 1, False:0})\n",
    "    df['WINDY_EVENT'] = df['EVENT_TYPE'].str.contains('Wind|Tornado|Thunderstorm|Cloud|Storm').map({True: 1, False:0})\n",
    "    df['WATER_EVENT'] = df['EVENT_TYPE'].str.contains('Flood|Marine|Rain|Hurricane|Tide|Lake|Seiche|Tsunami|Sleet|Water').map({True: 1, False:0})\n",
    "    df.loc[:,'CZ_TIMEZONE'] = df.loc[:,'CZ_TIMEZONE'].apply(lambda x: timezone_mapping(x))\n",
    "    df.loc[:,'BEGIN_AZIMUTH'] = df.loc[:,'BEGIN_AZIMUTH'].str.upper().apply(lambda x: dict_mapping(x) if dict_mapping(x) != None else x)\n",
    "    df.loc[:,'END_AZIMUTH'] = df.loc[:,'END_AZIMUTH'].str.upper().apply(lambda x: dict_mapping(x) if dict_mapping(x) != None else x)\n",
    "    \n",
    "    # Imputing string columns with missing values with NA\n",
    "    for col in impute_NA_list:\n",
    "        df[col] = df[col].astype('str').apply(lambda x: 'NA' if x=='nan' else x) # changed from N/A to NA\n",
    "        \n",
    "    # Imputing float columns having missing values with 0.0\n",
    "    for col in impute_zero_list:\n",
    "        df[col] = df[col].fillna(0.0)\n",
    "        \n",
    "    # Imputing latitude and longitudes with average value\n",
    "    # for col in impute_mean_list:\n",
    "    #     df[col] = df[col].fillna(np.mean)\n",
    "        \n",
    "    # Dropping text and ID columns\n",
    "    for col in drop_list:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "imputed_NOAA_df = impute_NOAA_data(NOAA_df.copy())\n",
    "imputed_NOAA_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb7e4bbe",
   "metadata": {
    "executionInfo": {
     "elapsed": 1966,
     "status": "ok",
     "timestamp": 1638594454776,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "eb7e4bbe"
   },
   "outputs": [],
   "source": [
    "#cleaned_df = pd.merge(imputed_NOAA_df, imputed_EPA_df, on='YEAR', how='inner')\n",
    "cleaned_df = imputed_NOAA_df\n",
    "cleaned_df.to_pickle('Data/cleaned_NAN_removed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "776cfc04",
   "metadata": {
    "executionInfo": {
     "elapsed": 1174,
     "status": "ok",
     "timestamp": 1638594457441,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "776cfc04"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "NOAA = pd.read_pickle('Data/cleaned_NAN_removed.pkl')\n",
    "\n",
    "# df_train = NOAA[(NOAA[\"YEAR\"] > 2005) & (NOAA[\"EVENT_TYPE\"]=='Flood')]\n",
    "\n",
    "# df_train = NOAA[(NOAA[\"EVENT_TYPE\"]=='Tornado')]\n",
    "\n",
    "df_train = NOAA[(NOAA[\"YEAR\"] > 2005)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7oC_ggAh_-dB",
   "metadata": {
    "id": "7oC_ggAh_-dB"
   },
   "outputs": [],
   "source": [
    "# Normalizing DAMAGE_PROPERTY variable - if required\n",
    "\n",
    "# df_train['HasDamage'] = pd.Series(len(df_train['DAMAGE_PROPERTY']), index=df_train.index)\n",
    "# df_train['HasDamage'] = 0 \n",
    "# df_train.loc[df_train['DAMAGE_PROPERTY']>0,'HasDamage'] = 1\n",
    "\n",
    "# df_train.loc[df_train['HasDamage']==1,'DAMAGE_PROPERTY'] = np.log(df_train['DAMAGE_PROPERTY'])\n",
    "\n",
    "# df_train.drop(columns=['HasDamage'], inplace=True)\n",
    "\n",
    "# df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84YtYYSzCAAC",
   "metadata": {
    "id": "84YtYYSzCAAC"
   },
   "outputs": [],
   "source": [
    "# assign labels to categorical columns - RUN THIS ONLY IF YOU WANT TO DO \"LABEL ENCODING\" OF CATEGORICAL VARIABLES\n",
    "\n",
    "def mapping(xx):\n",
    "    dict = {}\n",
    "    count = -1\n",
    "    for x in xx:\n",
    "        dict[x] = count + 1\n",
    "        count = count + 1\n",
    "    return dict\n",
    "\n",
    "for i in ['STATE', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE',  'MAGNITUDE_TYPE', 'BEGIN_AZIMUTH', 'END_AZIMUTH', 'FLOOD_CAUSE', 'TOR_F_SCALE', 'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_CZ_STATE', 'TOR_OTHER_CZ_NAME'\n",
    "          , 'CZ_NAME',  'TOR_OTHER_CZ_NAME', 'BEGIN_LOCATION', 'END_LOCATION','CZ_TIMEZONE']:\n",
    "    unique_tag = df_train[i].value_counts().keys().values\n",
    "    dict_mapping = mapping(unique_tag)\n",
    "    df_train[i] = df_train[i].map(lambda x: dict_mapping[x] if x in dict_mapping.keys() else -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "H-ynoqby8kTU",
   "metadata": {
    "id": "H-ynoqby8kTU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CZ_NAME</th>\n",
       "      <th>INJURIES_DIRECT</th>\n",
       "      <th>INJURIES_INDIRECT</th>\n",
       "      <th>DEATHS_DIRECT</th>\n",
       "      <th>DEATHS_INDIRECT</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>TOR_LENGTH</th>\n",
       "      <th>TOR_WIDTH</th>\n",
       "      <th>TOR_OTHER_CZ_STATE</th>\n",
       "      <th>...</th>\n",
       "      <th>END_AZIMUTH_7</th>\n",
       "      <th>END_AZIMUTH_8</th>\n",
       "      <th>END_AZIMUTH_9</th>\n",
       "      <th>END_AZIMUTH_10</th>\n",
       "      <th>END_AZIMUTH_11</th>\n",
       "      <th>END_AZIMUTH_12</th>\n",
       "      <th>END_AZIMUTH_13</th>\n",
       "      <th>END_AZIMUTH_14</th>\n",
       "      <th>END_AZIMUTH_15</th>\n",
       "      <th>END_AZIMUTH_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101990</th>\n",
       "      <td>2006</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101991</th>\n",
       "      <td>2006</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101992</th>\n",
       "      <td>2006</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101993</th>\n",
       "      <td>2006</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101994</th>\n",
       "      <td>2006</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        YEAR  CZ_NAME  INJURIES_DIRECT  INJURIES_INDIRECT  DEATHS_DIRECT  \\\n",
       "101990  2006      149                0                  0              0   \n",
       "101991  2006      149                0                  0              0   \n",
       "101992  2006      154                0                  0              0   \n",
       "101993  2006      127                0                  0              0   \n",
       "101994  2006     1200                0                  0              0   \n",
       "\n",
       "        DEATHS_INDIRECT  DAMAGE_PROPERTY  TOR_LENGTH  TOR_WIDTH  \\\n",
       "101990                0           3000.0           0          0   \n",
       "101991                0           3000.0           0          0   \n",
       "101992                0           2000.0           0          0   \n",
       "101993                0              0.0           0          0   \n",
       "101994                0              0.0           0          0   \n",
       "\n",
       "        TOR_OTHER_CZ_STATE  ...  END_AZIMUTH_7  END_AZIMUTH_8  END_AZIMUTH_9  \\\n",
       "101990                   0  ...              0              0              0   \n",
       "101991                   0  ...              0              0              0   \n",
       "101992                   0  ...              0              0              0   \n",
       "101993                   0  ...              0              0              0   \n",
       "101994                   0  ...              0              0              0   \n",
       "\n",
       "        END_AZIMUTH_10  END_AZIMUTH_11  END_AZIMUTH_12  END_AZIMUTH_13  \\\n",
       "101990               0               0               0               0   \n",
       "101991               0               0               0               0   \n",
       "101992               0               0               0               0   \n",
       "101993               0               0               0               0   \n",
       "101994               0               0               0               0   \n",
       "\n",
       "        END_AZIMUTH_14  END_AZIMUTH_15  END_AZIMUTH_16  \n",
       "101990               0               0               0  \n",
       "101991               0               0               0  \n",
       "101992               1               0               0  \n",
       "101993               0               0               0  \n",
       "101994               0               0               0  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET DUMMIES and assign labels to categorical columns\n",
    "\n",
    "def mapping(xx):\n",
    "    dict = {}\n",
    "    count = -1\n",
    "    for x in xx:\n",
    "        dict[x] = count + 1\n",
    "        count = count + 1\n",
    "    return dict\n",
    "\n",
    "for i in ['CZ_NAME', 'BEGIN_LOCATION', 'END_LOCATION',\t'TOR_OTHER_CZ_STATE',\t'TOR_OTHER_CZ_NAME']:\n",
    "    unique_tag = df_train[i].value_counts().keys().values\n",
    "    dict_mapping = mapping(unique_tag)\n",
    "    df_train[i] = df_train[i].map(lambda x: dict_mapping[x] if x in dict_mapping.keys() else -1)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, prefix=['STATE', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_TIMEZONE', 'BEGIN_AZIMUTH', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'TOR_F_SCALE', 'END_AZIMUTH']\n",
    "                          , columns=['STATE', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_TIMEZONE','BEGIN_AZIMUTH', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'TOR_F_SCALE', 'END_AZIMUTH'])\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "gc9pwLQ4hQbP",
   "metadata": {
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1638594488689,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "gc9pwLQ4hQbP"
   },
   "outputs": [],
   "source": [
    "# remove any pending NAN from DAMAGE_CROPS and DAMAGE_PROPERTY\n",
    "\n",
    "# df_train.dropna(subset=[\"DAMAGE_PROPERTY\"], inplace=True)\n",
    "# df_train.dropna(subset=[\"DAMAGE_CROPS\"], inplace=True)\n",
    "\n",
    "# check for NULL values\n",
    "for i in df_train.columns:\n",
    "    if df_train[i].isna().sum() > 0:\n",
    "        print(df_train[i].name, \":\", df_train[i].isna().sum(), \"\\n\")\n",
    "        print((df_train[i].isna().sum()/df_train.shape[0])*100, \"\\n\")\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20d5da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_pickle('Data/df_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8GX2aHA7cKtz",
   "metadata": {
    "id": "8GX2aHA7cKtz"
   },
   "outputs": [],
   "source": [
    "# correlation\n",
    "\n",
    "corrmat = df_train.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(22, 19))\n",
    "sns.heatmap(corrmat, vmax=1.0, square=True)\n",
    "plt.show()\n",
    "\n",
    "#DAMAGE_PROPERTY correlation matrix\n",
    "# k = 20 #number of variables for heatmap\n",
    "# cols = corrmat.nlargest(k, 'DAMAGE_PROPERTY')['DAMAGE_PROPERTY'].index\n",
    "# cm = np.corrcoef(df_train[cols].values.T)\n",
    "# sns.set(font_scale=1.25)\n",
    "# hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 15}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bmDBiqPZJjX8",
   "metadata": {
    "executionInfo": {
     "elapsed": 1651,
     "status": "ok",
     "timestamp": 1638594501167,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "bmDBiqPZJjX8"
   },
   "outputs": [],
   "source": [
    "# Create train test split\n",
    "X = df_train.loc[:, ~df_train.columns.isin(['DAMAGE_PROPERTY'])]\n",
    "\n",
    "Y = df_train['DAMAGE_PROPERTY']\n",
    "\n",
    "# split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100)\n",
    "\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lkljK9xmpXTm",
   "metadata": {
    "id": "lkljK9xmpXTm"
   },
   "outputs": [],
   "source": [
    "# Scaling the data if required\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# sc.fit(X_train)\n",
    "# X_train = sc.transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "\n",
    "# X_train = (X_train - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rWZsVuLpisfz",
   "metadata": {
    "id": "rWZsVuLpisfz"
   },
   "outputs": [],
   "source": [
    "# PCA code if we use one-hot encoding\n",
    "\n",
    "# pca = PCA(0.95)\n",
    "# pca = PCA(n_components=25)\n",
    "# pca.fit(X_train)\n",
    "\n",
    "\n",
    "# X_train = pca.transform(X_train)\n",
    "# X_test = pca.transform(X_test)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# pca.components_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dO-72o_aLMAY",
   "metadata": {
    "id": "dO-72o_aLMAY"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_score = [round(value) for value in y_pred]\n",
    "\n",
    "MSE = mean_squared_error(y_pred,y_test)\n",
    "print(MSE)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "\n",
    "print(r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BinuTnA1kFSG",
   "metadata": {
    "id": "BinuTnA1kFSG"
   },
   "outputs": [],
   "source": [
    "clf_rf = RandomForestRegressor(n_estimators= 100, oob_score = 'TRUE', n_jobs = -1,random_state =50, max_features = \"auto\", min_samples_leaf = 50)\n",
    "# RandomForestRegressor(max_depth=10, random_state=0)\n",
    "\n",
    "# perform training\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "\n",
    "# prediction on test using all features\n",
    "y_pred = clf_rf.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_pred,y_test)\n",
    "print(MSE)\n",
    "\n",
    "print(clf_rf.score(X_train,y_train))\n",
    "\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bUWHdpy5qGfi",
   "metadata": {
    "id": "bUWHdpy5qGfi"
   },
   "outputs": [],
   "source": [
    "# np.argsort(clf_rf.feature_importances_)[::-1]\n",
    "df_train.columns[np.argsort(clf_rf.feature_importances_)[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gtSLh9k6qegX",
   "metadata": {
    "id": "gtSLh9k6qegX"
   },
   "outputs": [],
   "source": [
    "# rfc = XGBRegressor()\n",
    "\n",
    "# parameters = {\n",
    "#     'max_depth': range(2, 10, 1),\n",
    "#     'n_estimators': range(60, 220, 40),\n",
    "#     'learning_rate': [0.1, 0.01, 0.05]\n",
    "# }\n",
    "\n",
    "# xgb = GridSearchCV(rfc, parameters, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "xgb = XGBRegressor(learning_rate =0.01,subsample =0.7, max_depth=5, n_estimators=100, colsample_bytree=0.8)\n",
    "xgb.fit(X_train, y_train, eval_set=[(X_train, y_train)])\n",
    "\n",
    "# print(xgb.feature_importances_)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_score = [round(value) for value in y_pred]\n",
    "\n",
    "MSE = mean_squared_error(y_pred,y_test)\n",
    "print(MSE)\n",
    "\n",
    "print(xgb.score(X_train,y_train))\n",
    "\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-3Ejvm9U2OGO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48965,
     "status": "ok",
     "timestamp": 1638483635387,
     "user": {
      "displayName": "Ishan Kuchroo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqL1VsIRtQxbdkbnsamPgdrsuFIrzKzg-MbkLU=s64",
      "userId": "15481571572392513977"
     },
     "user_tz": 300
    },
    "id": "-3Ejvm9U2OGO",
    "outputId": "f4965022-db7c-451b-8cfe-f622c2192ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.03581437685072386\n"
     ]
    }
   ],
   "source": [
    "alpha_range = 10.**np.arange(-2, 3)\n",
    "\n",
    "ridgeregcv = RidgeCV(alphas=alpha_range, normalize=True, scoring='neg_mean_squared_error')\n",
    "ridgeregcv.fit(X_train, y_train)\n",
    "ridgeregcv.alpha_\n",
    "\n",
    "y_pred = ridgeregcv.predict(X_test)\n",
    "\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vvsfjo-l2iwe",
   "metadata": {
    "id": "vvsfjo-l2iwe"
   },
   "outputs": [],
   "source": [
    "lassoregcv = LassoCV(n_alphas=100, normalize=True, random_state=1)\n",
    "lassoregcv.fit(X_train, y_train)\n",
    "print('alpha : ',lassoregcv.alpha_)\n",
    "\n",
    "y_pred = lassoregcv.predict(X_test)\n",
    "\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HwelkHv8vBl3",
   "metadata": {
    "id": "HwelkHv8vBl3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor()\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, Y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1,verbose=3)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HU_88HB5-e5L",
   "metadata": {
    "id": "HU_88HB5-e5L"
   },
   "outputs": [],
   "source": [
    "# identify outliers with standard deviation\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = NOAA_df\n",
    "# calculate summary statistics\n",
    "data_mean, data_std = mean(data), std(data)\n",
    "# identify outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "# remove outliers\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print('Non-outlier observations: %d' % len(outliers_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DBwNmZOnt4mk",
   "metadata": {
    "id": "DBwNmZOnt4mk"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "# identify outliers in the training dataset\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "# select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "# summarize the shape of the updated training dataset\n",
    "print(X_train.shape, y_train.shape)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Model_remove_NAN_IK_v1.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
